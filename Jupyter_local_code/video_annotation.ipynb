{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25bd60e0-f436-41ed-ac9a-50a76ce7ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'GOPR1077_tr.mp4'\n",
    "model_path = 'best.pt' # path to .pt file from YOLOv10 notebook\n",
    "\n",
    "# dimensions of photos the model was trained on\n",
    "IMAGE_WIDTH = 416\n",
    "IMAGE_HEIGHT = 416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "edccb1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q av pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a58fcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLOv10\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "import cv2\n",
    "import av, os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "295e1e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# im_pil = Image.open(\"oyster_test.jpg\")\n",
    "# image = np.array(im_pil)https://github.com/roboflow/notebooks/blob/main/notebooks/train-yolov10-object-detection-on-custom-dataset.ipynb\n",
    "# image_2 = np.array(Image.open('problem_photo_small.jpg'))\n",
    "# print(im_pil.size)\n",
    "# ann_img = run_pred(image_2)\n",
    "# sv.plot_image(ann_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b14fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated video has been saved as GOPR1077_tr_annotated.mp4\n"
     ]
    }
   ],
   "source": [
    "def annotate_image(input_img, label_annotator, bounding_box_annotator, model_pred, verbose = False):\n",
    "    cont_img = np.ascontiguousarray(input_img, dtype=np.uint8)\n",
    "    results = model_pred(cont_img, conf=0.10, verbose = verbose)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "    annotated_image = bounding_box_annotator.annotate(\n",
    "        scene=input_img, detections=detections)\n",
    "    annotated_image = label_annotator.annotate(\n",
    "        scene=annotated_image, detections=detections)\n",
    "    return(annotated_image)\n",
    "\n",
    "def annotate_video(in_path, out_path = '.', model_file = 'best.pt', im_width = IMAGE_WIDTH, im_height = IMAGE_HEIGHT):\n",
    "    bba = sv.BoundingBoxAnnotator()\n",
    "    la = sv.LabelAnnotator()\n",
    "    model = YOLOv10(model_file)\n",
    "\n",
    "    container = av.open(in_path)\n",
    "    stream_vid = container.streams.video[0]\n",
    "    fname = in_path.rsplit('/', 1)[-1]\n",
    "    per_index = fname.index('.')\n",
    "    out_path = f'{out_path}/{fname[:per_index]}_annotated.mp4'\n",
    "    outp = av.open(out_path, 'w')\n",
    "    codec_name = stream_vid.codec_context.name\n",
    "    fps = stream_vid.codec_context.rate\n",
    "    output_stream = outp.add_stream(codec_name, str(fps))\n",
    "    output_stream.width = im_width\n",
    "    output_stream.height = im_height\n",
    "    output_stream.pix_fmt = stream_vid.codec_context.pix_fmt\n",
    "    for index, frame in enumerate(container.decode(stream_vid)):\n",
    "        pil_img = frame.to_image()\n",
    "        np_img = np.array(pil_img)\n",
    "        np_img_resize = cv2.resize(np_img, (im_width, im_height))\n",
    "        np_rot = np_img_resize[:, :, ::-1]\n",
    "        small_pil_img = Image.fromarray(np_rot)\n",
    "        np_image_2 = np.array(small_pil_img)\n",
    "        an_mg = annotate_image(np_image_2, label_annotator = la, bounding_box_annotator=bba, model_pred = model, verbose = False)\n",
    "        frame_out = av.VideoFrame.from_ndarray(an_mg, format='bgr24')\n",
    "        pkt = output_stream.encode(frame_out)\n",
    "        outp.mux(pkt)\n",
    "    container.close()\n",
    "    outp.close()\n",
    "\n",
    "    print(f'Annotated video has been saved as {out_path}')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "53bafc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# without any modification == 41.5\n",
    "# with modification == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1244e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
