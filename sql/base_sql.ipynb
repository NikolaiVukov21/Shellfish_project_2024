{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d424f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q sql av pillow pandas sqlalchemy ipython-sql pymysql roboflow git+https://github.com/THU-MIG/yolov10.git supervision huggingface_hub bottleneck==1.3.6 numexpr==2.8.4 wget gcloud google google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35088997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: httplib2==0.15.0 in /mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages (0.15.0)\n",
      "Collecting google-api-python-client==1.6\n",
      "  Using cached google_api_python_client-1.6.0-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: oauth2client<5.0.0dev,>=1.5.0 in /mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages (from google-api-python-client==1.6) (4.1.3)\n",
      "Requirement already satisfied: six<2dev,>=1.6.1 in /mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages (from google-api-python-client==1.6) (1.16.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages (from google-api-python-client==1.6) (3.0.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client==1.6) (0.6.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client==1.6) (0.4.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages (from oauth2client<5.0.0dev,>=1.5.0->google-api-python-client==1.6) (4.0)\n",
      "Using cached google_api_python_client-1.6.0-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: google-api-python-client\n",
      "  Attempting uninstall: google-api-python-client\n",
      "    Found existing installation: google-api-python-client 1.7.8\n",
      "    Uninstalling google-api-python-client-1.7.8:\n",
      "      Successfully uninstalled google-api-python-client-1.7.8\n",
      "Successfully installed google-api-python-client-1.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install httplib2==0.15.0 google-api-python-client==1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9de8481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from pymysql.err import IntegrityError, OperationalError\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "import cv2\n",
    "import av\n",
    "from PIL import Image\n",
    "import shutil as sh\n",
    "import re\n",
    "from roboflow import Roboflow\n",
    "import cv2\n",
    "from ultralytics import YOLOv10\n",
    "import wget\n",
    "from time import time\n",
    "from gcloud import storage\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa7846ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = os.path.join('.', 'Files_local')\n",
    "temp_weights = os.path.join(temp_folder, 'Weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8310e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bba = sv.BoxCornerAnnotator()\n",
    "la = sv.LabelAnnotator(text_scale = 0.4, text_padding = 1)\n",
    "\n",
    "def annotate_image(input_img, model, label_annotator = la, bounding_box_annotator = bba, verbose = False, conf = True, conf_level = 0.05):\n",
    "    \n",
    "    cont_img = np.ascontiguousarray(input_img, dtype=np.uint8)\n",
    "    results = model(cont_img, conf=conf_level, verbose = verbose)[0]\n",
    "    conf_array = np.array(results.boxes.conf.cpu())\n",
    "    conf_ls_str  = [str(round(x * 100) ) + '%' for x in conf_array]\n",
    "    tot_time = sum([x for x in results.speed.values()])\n",
    "    \n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "    annotated_image = bounding_box_annotator.annotate(\n",
    "        scene=input_img, detections=detections)\n",
    "    num_oysters = detections.xyxy.shape[0]\n",
    "    annotated_image = label_annotator.annotate(\n",
    "        scene=annotated_image, detections=detections, labels = conf_ls_str)\n",
    "    return(annotated_image, num_oysters, tot_time, detections)\n",
    "\n",
    "\n",
    "def annotate_video(input_vid, model, out_location = '.', im_width = 416, im_height = 416, conf_level = 0.3):\n",
    "    tot_oysters = 0\n",
    "    tot_frame = 0\n",
    "    \n",
    "    bba = sv.BoundingBoxAnnotator()\n",
    "    la = sv.LabelAnnotator()\n",
    "\n",
    "    container = av.open(input_vid)\n",
    "    stream_vid = container.streams.video[0]\n",
    "    fname = input_vid.rsplit('/', 1)[-1]\n",
    "    per_index = fname.index('.')\n",
    "    out_path = os.path.join(out_location, f'{fname[:per_index]}_annotated.mp4')\n",
    "    outp = av.open(out_path, 'w')\n",
    "    codec_name = stream_vid.codec_context.name\n",
    "    fps = stream_vid.codec_context.rate\n",
    "    output_stream = outp.add_stream(codec_name, str(fps))\n",
    "    output_stream.width = im_width\n",
    "    output_stream.height = im_height\n",
    "    output_stream.pix_fmt = stream_vid.codec_context.pix_fmt\n",
    "    start = time()\n",
    "    for index, frame in enumerate(container.decode(stream_vid)):\n",
    "        pil_img = frame.to_image()\n",
    "        np_img = np.array(pil_img)\n",
    "        np_img_resize = cv2.resize(np_img, (im_width, im_height))\n",
    "        np_rot = np_img_resize[:, :, ::-1]\n",
    "        small_pil_img = Image.fromarray(np_rot)\n",
    "        np_image_2 = np.array(small_pil_img)\n",
    "        an_mg, num_oysters, _, _2z = annotate_image(np_image_2, model, conf_level = conf_level)\n",
    "        tot_oysters += num_oysters\n",
    "        frame_out = av.VideoFrame.from_ndarray(an_mg, format='bgr24')\n",
    "        pkt = output_stream.encode(frame_out)\n",
    "        outp.mux(pkt)\n",
    "    end = time()\n",
    "    net_time = end - start\n",
    "    container.close()\n",
    "    outp.close()\n",
    "    ann_rate = (index / fps) / net_time # ratio of time to annotate versus length of video\n",
    "    return tot_oysters / index, net_time, out_path, ann_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c7c659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_in_storage_g():\n",
    "    credentials_dict = {\n",
    "      \"type\": \"service_account\",\n",
    "      \"project_id\": \"molten-album-427115-q6\",\n",
    "      \"private_key_id\": \"e13a814af6d892a743443f3e37a63bb68813dcde\",\n",
    "      \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDCpC0/NQHI0yNr\\n7i/8AtS2pU2WFtsHU6ajhZLiMvrkhZL+cvGgOZMqbj1FxhtrpD3gmFNrnhObjuIY\\nJfBpCMRIWOOeNs87Lmrvpx/LcJsqaqsaOj1aVkMndCueM87eVJXqKHtqlz0DxYlw\\nlxbvYyb3ESO6AgXLI7LlLFuUr+llvjSdvJuDHszCiGWEVWUoDicVvv/OSQoGAKc7\\nZL2w4vO/m0k0Le1eAnBc429XYZccCDqFJ79Ci0rnqgcP9Q/de8ZKP8/OZzy6Coiy\\n/MlQxnDR/TqvdHfQ8MT50WCkoyshyuNBvH8jUt1aHRpIqFeApkmCQkPBhnRZ18by\\nBrC++RGLAgMBAAECggEAQNuQMDWriI3Cid5uot0WoF3owpCPH5viNS73SOSP8cII\\nvzzyAt/siAD/7dYboPyzmbloYr3j7rvn3wAVYgqHzUvBXSEKYMAQ5hacY5/8NGAi\\n77RkaUvBSM5PEoJU9oTdB4/BwDzxGeai65+NBuvVOhK+AudVouEcZX0obx1G+p2Y\\nCvrV8YoKg4ZK6yWtFs7w/JOxD7FYAN6OhsblN9aXVDfP8C3dFhSkPsUJzzjYXXHF\\nj70EqTNVEMFzpSTojPIoq/y0EqcxrVfpjy1z2NPAyug3Tk2XXpgpKvGZc2hCv+wx\\nw3uC6mGFzQajDwNxc8ASi10QQS56ytUYVPiMvwAzQQKBgQDfdUjSTCMCQjBjl8tQ\\nFDUXXQ4Vp33YlXbKYaxZLmwyISOejQ4FcyLE0ijRRZ0oMa/Hlm6E8i53AyiNvRVF\\nBQZQZ8TdWjXpvQFW7OlAuT8k6K1nV0ROoSW3N0BzOfz3yZcC4E5u+i0kPC0PXuGe\\n8KfZYzRDR51hvRT383TMLxr1uwKBgQDe/JNhKOqg3hGkjDIEzP7hlivpzpxmVHHE\\nl6Jyo3oqaQum5tP5mI9pqtWGpPkerpTnHC1lGWIfjL5hWwbVHcdKEEbByfDkdezQ\\noHVD6smmwSNY4htSYMasGNwKsCUJxhR8n9OZsUobssOE1U10vpXeQDYHD72+96L0\\nw54ud5EucQKBgG/NaK//dAyvPTK3QfxBAAc+gcuHz8lLjvHXSLoeJfg26HFttbQ4\\nVQ8Q72c1Y1o28fH0bDuMSH83T1ULY9bymqQkJzVw60SVUlRBmLrPdK5s1EW+Pejx\\na8Ntm4uLWexIKow/2j5gYbGdghYMrOovEmwL3JxE+pNqXVFpt+hpMR39AoGBAKJ8\\n0rheJHsM1zZcoqY06xZfY6iAUh+PMUfcZxe6YG8/FKqOUbDzpq2NOwNee9oLxZ2T\\nPtEI6iOrX595wUTS6kHiEm1sRgl0lRiBlHHlSQQmgSdnvBkPRDZr9wwixxqUKKGX\\npY29Tw9X+Hl3JXYI2xSVHcmPgukBctGBKmcZ4cVBAoGAIzNhwtXrNIBcNKeOlk8H\\nWtCDb4QsVY5vfAlo22I2E5WVaBlQ794aJBM1Zt5UPW/Emk6Bw1BkesxtdMbi49z/\\n2T0Hazy6utZkFdk30C7Cl4s/SwqoWbKEIP/xrjPqF78PZUDLy0mkwzHe+SC++MYv\\nCJbsRkDledgb+mhABbtpzMQ=\\n-----END PRIVATE KEY-----\\n\",\n",
    "      \"client_email\": \"cloud-storage-sa@molten-album-427115-q6.iam.gserviceaccount.com\",\n",
    "      \"client_id\": \"105767049463355191586\",\n",
    "      \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "      \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "      \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "      \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/cloud-storage-sa%40molten-album-427115-q6.iam.gserviceaccount.com\",\n",
    "      \"universe_domain\": \"googleapis.com\"\n",
    "    }\n",
    "\n",
    "    credentials = ServiceAccountCredentials.from_json_keyfile_dict(\n",
    "        credentials_dict\n",
    "    )\n",
    "    client = storage.Client(credentials=credentials, project='molten-album-427115-q6')\n",
    "    bkt = client.get_bucket('test_bucket_abc123')\n",
    "    return bkt\n",
    "\n",
    "b = sign_in_storage_g()\n",
    "\n",
    "def check_folder_exists_g(folder_to_upload, check_location, disable = False, bkt = b): # assume full installation\n",
    "    # assumes if one file is in the right location then they all are\n",
    "    if disable:\n",
    "        return True\n",
    "    cur_path = folder_to_upload\n",
    "    path_check_exist_g = check_location\n",
    "    all_items = os.listdir(cur_path)\n",
    "    for added_item in all_items: # searching for a file\n",
    "        cur_path = os.path.join(cur_path, added_item)\n",
    "        path_check_exist_g = os.path.join(path_check_exist_g, added_item)\n",
    "        cur_exists = False\n",
    "        if os.path.isfile(cur_path):\n",
    "            return path_exists_g(path_check_exist_g)\n",
    "        elif os.path.isdir(cur_path):\n",
    "            cur_exists = check_folder_exists_g(cur_path, path_check_exist_g)\n",
    "        if not cur_exists:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def upload_file_g(file_to_upload, new_name_with_path_g, bkt = b):\n",
    "    blob = bkt.blob(new_name_with_path_g)\n",
    "    blob.upload_from_filename(file_to_upload)\n",
    "    \n",
    "\n",
    "def upload_folder_g(folder_to_upload, new_name_with_path_g, bkt = b , level = 0, overwrite = False):\n",
    "    already_uploaded = False\n",
    "    if level == 0: # check if already uploaded\n",
    "        already_uploaded = check_folder_exists_g(folder_to_upload, new_name_with_path_g)\n",
    "        level += 1\n",
    "    if os.path.exists(folder_to_upload) and (not already_uploaded or overwrite):\n",
    "        for item in os.listdir(folder_to_upload):\n",
    "            cur_path = os.path.join(folder_to_upload, item)\n",
    "            new_path_g = os.path.join(new_name_with_path_g, item)\n",
    "            if os.path.isfile(cur_path):\n",
    "                upload_file_g(cur_path, new_path_g)\n",
    "            elif os.path.isdir(new_path_g):\n",
    "                upload_folder_g(cur_path, new_path_g, level)\n",
    "    \n",
    "\n",
    "# upload_file('redownloaded.jpg', 'out_3.jpg')\n",
    "\n",
    "def download_file_g(file_to_download_g, new_name_with_path, bkt = b):\n",
    "    blob = bkt.blob(file_to_download_g)\n",
    "    blob.download_to_filename(new_name_with_path)\n",
    "\n",
    "# download_file('out_3.jpg', 'pulled_image.jpg')\n",
    "\n",
    "def make_folder_g(folder_name, bkt = b):\n",
    "    blob = bkt.blob(folder_name + '/')\n",
    "    blob.upload_from_string('')\n",
    "\n",
    "def path_exists_g(file, bkt = b):\n",
    "    blob = bkt.blob(file)\n",
    "    return blob.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cda71751",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file_g(\"/mnt/linuxlab/home/mstaus1/Desktop/Shellfish_project_2024/Oyster Test Videos/GOPR0018.MP4\", \"GOPR1077-23.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9327bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ext(fpath):\n",
    "    fname = fpath.rsplit('/', 1)[-1]\n",
    "    per_index = fname.index('.')\n",
    "    ext = fname[per_index + 1:].lower()\n",
    "    return ext\n",
    "\n",
    "def get_id_fname(f_out, fpath, id):\n",
    "    fname = fpath.rsplit('/', 1)[-1]\n",
    "    per_index = fname.index('.')\n",
    "    ext = fname[per_index + 1:].lower()\n",
    "    return os.path.join(f_out, f\"{fname[:per_index]}-{id}.{ext}\")\n",
    "\n",
    "def get_REPLACE_ID(column_id = 'Raw_File_ID', table='raw_files', column_rep='Filepath'):\n",
    "    cur.execute(f\"\"\"SELECT {column_id} from {table} where {column_rep} = 'REPLACE'\"\"\")\n",
    "    id = cur.fetchall()[-1][column_id]\n",
    "    return id\n",
    "\n",
    "def get_match(pattern, string):\n",
    "    matches = re.search(pattern, string)\n",
    "    if matches:\n",
    "        print(matches.group(1))\n",
    "        return(matches.group(1))\n",
    "    else:\n",
    "        raise ValueError(f'Improper string exported, couldn\\'t find {pattern} in the given text')\n",
    "\n",
    "        \n",
    "\n",
    "def delete_folder(name, base = \".\"):\n",
    "    fpath = os.path.join(base, name)\n",
    "    if os.path.exists(fpath):\n",
    "        for item in os.listdir(fpath):\n",
    "            new_path = os.path.join(fpath, item)\n",
    "            if os.path.isfile(new_path):\n",
    "                os.remove(new_path)\n",
    "            elif os.path.isdir(new_path):\n",
    "                delete_folder(item, fpath)\n",
    "        os.rmdir(fpath)\n",
    "                \n",
    "def make_folder(fpath, overwrite = False):\n",
    "    delete_folder(fpath, '.') if overwrite else None\n",
    "    if os.path.exists(fpath):\n",
    "        \n",
    "        print(f\"{fpath} already exists\")\n",
    "    else:\n",
    "        os.mkdir(fpath)\n",
    "        \n",
    "def get_temp_fname(fpath, temp_f = temp_folder):\n",
    "    fname = fpath.rsplit('/', 1)[-1]\n",
    "    return os.path.join(temp_folder, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8afcc56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Files_local already exists\n"
     ]
    }
   ],
   "source": [
    "if not path_exists_g('Files/'):\n",
    "    make_folder_g('Files')\n",
    "    make_folder_g('Files/Video_raw')\n",
    "    make_folder_g('Files/Video_ann')\n",
    "    make_folder_g('Files/Image_raw')\n",
    "    make_folder_g('Files/Image_ann')\n",
    "    make_folder_g('Files/Model')\n",
    "    make_folder_g('Files/Roboflow')\n",
    "make_folder(temp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4015dd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_main = 'test_4'\n",
    "cur_name = 'ab'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dbfd461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'1': 1}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_conn = pymysql.connect(\n",
    "    user=\"root\",\n",
    "    password=\"dbuserdbuser\",\n",
    "    host=\"localhost\",\n",
    "    port=3306,\n",
    "    database=db_main,\n",
    "    cursorclass=pymysql.cursors.DictCursor,\n",
    "    autocommit=True)\n",
    "\n",
    "cur = sql_conn.cursor()\n",
    "res = cur.execute(\"SELECT 1\")\n",
    "res = cur.fetchall()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "650cb013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Integrity Violated: Duplicate User with ab\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ab'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_user(name, password):\n",
    "    '''\n",
    "    Returns: name if query is successful, 0 if not\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        cur.execute(f\"INSERT INTO people (Username, Password, Time_Created) VALUES ('{name}', '{password}', CURRENT_TIMESTAMP );\")\n",
    "    except IntegrityError:\n",
    "        print(f\"Data Integrity Violated: Duplicate User with {name}\")\n",
    "    return name\n",
    "add_user(cur_name, '123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b79cee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_photo(name, fpath, notes = '', f_out = 'Files/Image_raw'):\n",
    "    '''\n",
    "    Returns: Index of added photo if successful, 0 if not\n",
    "    '''\n",
    "\n",
    "    im = Image.open(fpath)\n",
    "    width = im.size[0]\n",
    "    height = im.size[1]\n",
    "    fsize = os.stat(fpath).st_size\n",
    "    ext = get_ext(fpath)\n",
    "    f_temp = get_temp_fname(fpath)\n",
    "    im.save(f_temp)\n",
    "    cur.execute(f\"INSERT INTO raw_files (Username, Filepath, Size, Type, Extension, Notes, Width, Height, Time_Uploaded) VALUES ('{name}', 'REPLACE', {fsize}, 'Image', '{ext}', '{notes}', {width}, {height}, CURRENT_TIMESTAMP);\")\n",
    "    id = get_REPLACE_ID()\n",
    "\n",
    "    f_id_name_g = get_id_fname(f_out, fpath, id)\n",
    "#     print(f_temp, f_id_name)\n",
    "    upload_file_g(fpath, f_id_name_g)\n",
    "    cur.execute(f\"UPDATE raw_files SET Filepath = '{f_id_name_g}' WHERE Raw_File_ID = {id};\")\n",
    "    return id\n",
    "\n",
    "SOME_IMAGE_PATH = \"/mnt/linuxlab/home/mstaus1/Desktop/Shellfish_project_2024/Jupyter_local_code/problem_photo.jpg\"\n",
    "\n",
    "id_raw_photo = add_photo(cur_name, fpath = SOME_IMAGE_PATH, notes = 'from HPC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a12356f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/linuxlab/home/mstaus1/Desktop/Shellfish_project_2024/Jupyter_local_code/GOPR1077.MP4 Files/Video_raw/GOPR1077-30.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "def add_video(name, fpath, notes = '', f_out = 'Files/Video_raw'):\n",
    "    '''\n",
    "    Returns: Index of added video if successful, 0 if not\n",
    "    '''\n",
    "    cap = cv2.VideoCapture(fpath)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fsize = os.stat(fpath).st_size\n",
    "    ext = get_ext(fpath)\n",
    "    \n",
    "    cur.execute(f\"INSERT INTO raw_files (Username, Filepath, Size, Type, Extension, Notes, Width, Height, Time_Uploaded) VALUES ('{name}', 'REPLACE', {fsize}, 'Video', '{ext}', '{notes}', {width}, {height}, CURRENT_TIMESTAMP);\")\n",
    "    id = get_REPLACE_ID()\n",
    "    f_id_name_g = get_id_fname(f_out, fpath, id)\n",
    "    print(fpath, f_id_name_g)\n",
    "    upload_file_g(fpath, f_id_name_g)\n",
    "    \n",
    "    sh.copyfile(fpath, f_id_name_g)\n",
    "\n",
    "    cur.execute(f\"UPDATE raw_files SET Filepath = '{f_id_name_g}' WHERE Raw_File_ID = {id};\")\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    color_order = 'RGB' # FIXME - cant figure out how to extract from cv2 object\n",
    "\n",
    "    cur.execute(f\"INSERT INTO videos (Raw_File_ID, FPS, Color_Order) VALUES ('{id}', '{fps}', '{color_order}');\")\n",
    "\n",
    "    return id\n",
    "\n",
    "SOME_VIDEO_PATH = \"/mnt/linuxlab/home/mstaus1/Desktop/Shellfish_project_2024/Jupyter_local_code/GOPR1077.MP4\"\n",
    "id_raw_video = add_video(cur_name, SOME_VIDEO_PATH, notes='on new computer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f6619da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56de2ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rvk9Clz4ote58KBvCfU3\n",
      "curvy-oysters\n",
      "oysters-cjt7n\n",
      "19\n",
      "yolov8\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.1.34, to fix: `pip install ultralytics==8.0.196`\n",
      "./Files_local/Weights already exists\n"
     ]
    }
   ],
   "source": [
    "def add_roboflow(name, export_string, f_out = 'Files/Roboflow', f_weights = \"Files/Weights\"):\n",
    "    \n",
    "    '''\n",
    "    Returns: Index of added roboflow if successful, 0 if not\n",
    "    '''\n",
    "    pattern_api = r'api_key\\s*=\\s*\"([^\"]+)\"'\n",
    "    api_key_lab = get_match(pattern_api, export_string)\n",
    "\n",
    "    pattern_workspace = r'rf\\.workspace\\(\"([^\"]+)\"\\)'\n",
    "    workspace_lab = get_match(pattern_workspace, export_string)\n",
    "\n",
    "    pattern_project = r'project\\(\"([^\"]+)\"\\)'\n",
    "    project_lab = get_match(pattern_project, export_string)\n",
    "\n",
    "    pattern_version = r'version\\((\\d+)\\)'\n",
    "    version_lab = get_match(pattern_version, export_string)\n",
    "\n",
    "    pattern_download = r'\\bdownload\\(\"([^\"]+)\"\\)'\n",
    "    download_lab = get_match(pattern_download, export_string)\n",
    "    \n",
    "#     f_temp = get_temp_fname(f_out)\n",
    "    folder_name = f'{workspace_lab}_{project_lab}_{version_lab}_{download_lab}'\n",
    "    f_temp = os.path.join(temp_folder, folder_name)\n",
    "    \n",
    "    folder_g = os.path.join(f_out, folder_name)\n",
    "#     folder_roboflow = f\"{f_out}/{workspace_lab}_{project_lab}_{version_lab}_{download_lab}\"\n",
    "\n",
    "    # if not os.path.exists(folder_roboflow):\n",
    "    rf = Roboflow(api_key = api_key_lab)\n",
    "    project = rf.workspace(workspace_lab).project(project_lab)\n",
    "    version = project.version(version_lab)\n",
    "    dat = version.download(download_lab, location = f_temp)\n",
    "    \n",
    "    fpath = os.path.join(f_temp, 'data.yaml')\n",
    "    \n",
    "    with open(fpath) as f1:\n",
    "        lines = f1.readlines()\n",
    "    with open(fpath, 'w') as f2:\n",
    "        f2.writelines(lines[:-4])\n",
    "        f2.write(\"test: ../test/images\\ntrain: ../train/images\\nval: ../valid/images\\n\\n\")\n",
    "    \n",
    "    upload_folder_g(f_temp, folder_g)\n",
    "    \n",
    "    cur.execute(f\"INSERT INTO roboflow (Api_Key, Workspace, Project, Version, Download, Dataset_Location, Local_Path, Username, Timestamp) VALUES ('REPLACE', '{workspace_lab}', '{project_lab}', '{version_lab}', '{download_lab}', '{folder_g}', '{f_temp}', '{name}', CURRENT_TIMESTAMP);\")\n",
    "    \n",
    "    id = get_REPLACE_ID('Roboflow_ID', 'roboflow', 'Api_Key')\n",
    "    \n",
    "    cur.execute(f\"UPDATE roboflow SET Api_Key = '{api_key_lab}' WHERE Roboflow_ID = {id};\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    return id\n",
    "\n",
    "\n",
    "def get_weights(f_weights_g = 'Files/Weights'): # TODO - create weights table\n",
    "    temp_weights = os.path.join(temp_folder, \"Weights\")\n",
    "    make_folder(temp_weights)\n",
    "    prefix = \"https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10\"\n",
    "    versions = ['n', 's', 'm', 'b', 'x', 'l']\n",
    "    suffix = \".pt\"\n",
    "    for ver in versions:\n",
    "        cur_file = 'yolov10' + ver + suffix\n",
    "        web_path = prefix + ver + suffix\n",
    "        computer_path = os.path.join(temp_weights, cur_file)\n",
    "        if not os.path.exists(computer_path):\n",
    "            wget.download(web_path, out = temp_weights)\n",
    "    \n",
    "    upload_folder_g(temp_weights, f_weights_g)\n",
    "\n",
    "\n",
    "    \n",
    "id_rob = add_roboflow(cur_name, \\\n",
    "\"\"\"\n",
    "rf = Roboflow(api_key=\"Rvk9Clz4ote58KBvCfU3\")\n",
    "project = rf.workspace(\"curvy-oysters\").project(\"oysters-cjt7n\")\n",
    "dataset = project.version(19).download(\"yolov8\")\n",
    "\n",
    "\"\"\" )\n",
    "\n",
    "get_weights()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "43f6f22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Files_local/Weights already exists\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: './Files_local/Weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_325655/1178520101.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mid_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mid_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_rob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_325655/1178520101.py\u001b[0m in \u001b[0;36madd_model\u001b[0;34m(roboflow_ID, f_out, size_mod, weights_path_g, epochs, batch)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmake_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdownload_file_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_full_file_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_325655/106959281.py\u001b[0m in \u001b[0;36mdownload_file_g\u001b[0;34m(file_to_download_g, new_name_with_path, bkt)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload_file_g\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_to_download_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_name_with_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbkt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbkt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_to_download_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_to_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_name_with_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# download_file('out_3.jpg', 'pulled_image.jpg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/gcloud/storage/blob.py\u001b[0m in \u001b[0;36mdownload_to_filename\u001b[0;34m(self, filename, encryption_key, client)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mraises\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mgcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFound\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \"\"\"\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m             self.download_to_file(file_obj, encryption_key=encryption_key,\n\u001b[1;32m    369\u001b[0m                                   client=client)\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: './Files_local/Weights'"
     ]
    }
   ],
   "source": [
    "def add_model(roboflow_ID, f_out = \"Files/Model\", size_mod = 'n', weights_path_g = \"Files/Weights\", epochs = 10, batch = 32):\n",
    "    weights_file = f\"yolov10{size_mod}.pt\"\n",
    "    weights_full_file_g  = os.path.join(weights_path_g, weights_file)\n",
    "    \n",
    "    make_folder(temp_weights)\n",
    "    weights_full_file = os.path.join(weightw)\n",
    "    download_file_g(weights_full_file_g, temp_weights)\n",
    "    \n",
    "    \n",
    "    cur.execute(f\"SELECT * FROM roboflow WHERE Roboflow_ID = {roboflow_ID}\")\n",
    "    res = cur.fetchall()[-1]\n",
    "    pt = os.path.join(os.getcwd(), res['Dataset_Location'][len('.\\\\'):], 'data.yaml')\n",
    "    samp_photo = os.path.join(res['Dataset_Location'], 'test/images')\n",
    "    pt_rep = pt.replace('\\\\', '/')\n",
    "    !yolo task=detect mode=train epochs={epochs} batch={batch} plots=False model={weights_file} data={pt_rep}\n",
    "    \n",
    "    \n",
    "    first_photo = os.listdir(samp_photo)[0]\n",
    "    im = Image.open(os.path.join(samp_photo, first_photo))\n",
    "    width = im.size[0]\n",
    "    height = im.size[1]\n",
    "                                                               \n",
    "    cur.execute(f\"\"\"INSERT INTO models (Timestamp_Created, Model_Points_Path, Version, \n",
    "                Hyperparams, Epoch, Batch, Model_Type, Width_Training_Images, Height_Training_Images, \n",
    "                Size, Roboflow_ID) values (CURRENT_TIMESTAMP, 'REPLACE', 10, NULL, {epochs}, {batch}, \n",
    "                'YOLO', {width}, {height}, '{size_mod}', {roboflow_ID})\n",
    "                \"\"\")\n",
    "    \n",
    "    id_mod = get_REPLACE_ID(column_id = 'Model_ID', table='models', column_rep='Model_Points_Path')\n",
    "    model_path = f'./Files/Model/{id_mod}.pt'\n",
    "    os.rename('./runs/detect/train/weights/best.pt', model_path)\n",
    "    \n",
    "    cur.execute(f\"UPDATE models SET Model_Points_Path = '{model_path}' WHERE Model_ID = {id_mod};\")\n",
    "\n",
    "    delete_folder('runs')\n",
    "    return id_mod\n",
    "\n",
    "id_mod = add_model(id_rob,epochs=1, size_mod = 'm')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a917f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ann_img(Raw_File_ID, Model_ID, threshold = 0.3, notes = '', f_out = 'Files/Image_ann'):\n",
    "    try:\n",
    "        cur.execute(f\"SELECT * FROM raw_files WHERE Raw_File_ID = {Raw_File_ID}\")\n",
    "        cur_photo = cur.fetchall()[-1]\n",
    "\n",
    "        cur.execute(f\"SELECT * FROM models WHERE Model_ID = {Model_ID}\")\n",
    "        cur_model = cur.fetchall()[-1]\n",
    "\n",
    "        #     print(cur_photo, cur_model)\n",
    "\n",
    "\n",
    "        im = Image.open(cur_photo['Filepath'])\n",
    "        np_img = np.array(im)\n",
    "        model = YOLOv10(cur_model['Model_Points_Path'])\n",
    "#         print(model)\n",
    "        annot, num_oysters, tot_time, end_ann_data = annotate_image(np_img, model, conf_level = threshold)\n",
    "#         print(end_ann_data)\n",
    "        \n",
    "\n",
    "        cur.execute(f\"INSERT INTO annotated_files (Raw_File_ID, Model_ID, Annotated_Filepath, Time_to_Annotate, Confidence_Threshold, Notes, Timestamp) VALUES ('{Raw_File_ID}', '{Model_ID}', 'REPLACE', '{tot_time}', {threshold}, '{notes}', CURRENT_TIMESTAMP);\")\n",
    "        id = get_REPLACE_ID(column_id = 'Ann_File_ID', table='annotated_files', column_rep='Annotated_Filepath')\n",
    "        f_id_name = get_id_fname(f_out, cur_photo['Filepath'], id)\n",
    "#         print(f_id_name)\n",
    "        im_f = Image.fromarray(annot)\n",
    "        im_f.save(f_id_name)\n",
    "        \n",
    "                \n",
    "        cur.execute(f\"UPDATE annotated_files SET Annotated_Filepath = '{f_id_name}' WHERE Ann_File_ID = {id};\")\n",
    "        cur.execute(f\"INSERT INTO annotated_photos (Ann_File_ID, Number_of_Oysters) VALUES ({id}, {num_oysters})\")\n",
    "        \n",
    "        coord = end_ann_data.xyxy\n",
    "        conf = end_ann_data.confidence\n",
    "        names = end_ann_data.data['class_name']\n",
    "        class_num = end_ann_data.class_id\n",
    "        for idx in range(len(coord)):\n",
    "#             print('Here')\n",
    "            coord_cur = coord[idx]\n",
    "            cur.execute(f\"INSERT INTO oysters_in_photo (Ann_File_ID, Confidence, X1, Y1, X2, Y2, Class, Class_Index) VALUES ({id}, {conf[idx]}, {coord_cur[0]}, {coord_cur[1]}, {coord_cur[2]}, {coord_cur[3]}, '{names[idx]}', {class_num[idx]});\")\n",
    "        return id\n",
    "    except IntegrityError:\n",
    "        cur.execute(f\"SELECT Ann_File_ID FROM annotated_files WHERE Raw_File_ID = {Raw_File_ID} AND Model_ID = {Model_ID}\")\n",
    "        return(cur.fetchall()[-1]['Ann_File_ID'])\n",
    "cur.execute(f\"DELETE FROM oysters_in_photo WHERE Ann_File_ID = {ann_photo_id};\")  \n",
    "cur.execute(f\"DELETE FROM annotated_photos WHERE Ann_File_ID = {ann_photo_id};\")\n",
    "cur.execute(f\"DELETE FROM annotated_files WHERE Ann_File_ID = {ann_photo_id};\")\n",
    "\n",
    "ann_photo_id = ann_img(id_raw_photo, id_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35d8d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_video(Raw_File_ID, Model_ID, notes = '', f_out = 'Files/Video_ann', threshold = 0.3):\n",
    "    try:\n",
    "        cur.execute(f\"SELECT * FROM raw_files WHERE Raw_File_ID = {Raw_File_ID}\")\n",
    "        cur_video = cur.fetchall()[-1]\n",
    "\n",
    "        cur.execute(f\"SELECT * FROM models WHERE Model_ID = {Model_ID}\")\n",
    "        cur_model = cur.fetchall()[-1]\n",
    "        \n",
    "        cur.execute(f\"SELECT * from annotated_files WHERE Model_ID = {Model_ID} AND Raw_File_ID = {Raw_File_ID}\")\n",
    "        res = cur.fetchall()\n",
    "        if res:\n",
    "            return res[-1]['Ann_File_ID']\n",
    "#             raise IntegrityError(\"The video has already been annotated by this model\")\n",
    "        \n",
    "        model = YOLOv10(cur_model['Model_Points_Path'])\n",
    "        \n",
    "        avg_oysters, time_s, out_path, ann_rate = annotate_video(cur_video['Filepath'], model, out_location = f_out, conf_level = threshold)\n",
    "        \n",
    "        cur.execute(f\"INSERT INTO annotated_files (Raw_File_ID, Model_ID, Annotated_Filepath, Time_to_Annotate, Confidence_Threshold, Notes, Timestamp) VALUES ('{Raw_File_ID}', '{Model_ID}', 'REPLACE', '{time_s * 1000}', {threshold}, '{notes}', CURRENT_TIMESTAMP);\")\n",
    "        \n",
    "        id = get_REPLACE_ID(column_id = 'Ann_File_ID', table='annotated_files', column_rep='Annotated_Filepath')\n",
    "        \n",
    "        f_id_name = get_id_fname(f_out, cur_video['Filepath'], id)\n",
    "        \n",
    "        cur.execute(f\"UPDATE annotated_files SET Annotated_Filepath = '{f_id_name}' WHERE Ann_File_ID = {id};\")\n",
    "\n",
    "        os.rename(out_path, f_id_name)\n",
    "\n",
    "        cur.execute(f\"INSERT INTO annotated_videos (Ann_File_ID, Annotation_Rate, Tracing, Average_Number_of_Oysters) VALUES ({id}, {ann_rate}, 0, {avg_oysters})\")\n",
    "        \n",
    "        return id\n",
    "    except IntegrityError:\n",
    "        cur.execute(f\"SELECT Ann_File_ID FROM annotated_files WHERE Raw_File_ID = {Raw_File_ID} AND Model_ID = {Model_ID}\")\n",
    "        return(cur.fetchall()[-1]['Ann_File_ID'])\n",
    "\n",
    "    \n",
    "id_vid = ann_video(id_raw_video, id_mod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba45b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_folder(\"./Files/tmp\")\n",
    "# print(os.listdir('.'))\n",
    "# os.rename('./runs/detect/train/weights/best.pt', './Files/Model/f1/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ffb203",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id_raw_photo)\n",
    "print(id_raw_video)\n",
    "print(id_rob)\n",
    "print(id_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25291475",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_folder('runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a157edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_folder('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c68e964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
