{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d424f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q sql av pillow pandas sqlalchemy ipython-sql pymysql roboflow git+https://github.com/THU-MIG/yolov10.git supervision huggingface_hub bottleneck==1.3.6 numexpr==2.8.4 wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b9de8481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from pymysql.err import IntegrityError, OperationalError\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "import cv2\n",
    "import av\n",
    "from PIL import Image\n",
    "import shutil as sh\n",
    "import re\n",
    "from roboflow import Roboflow\n",
    "import cv2\n",
    "from ultralytics import YOLOv10\n",
    "import wget\n",
    "\n",
    "model_path = '../Jupyter_local_code/best.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8310e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLOv10(model_path)\n",
    "bba = sv.BoxCornerAnnotator()\n",
    "la = sv.LabelAnnotator(text_scale = 0.4, text_padding = 1)\n",
    "\n",
    "def annotate_image(input_img, model, label_annotator = la, bounding_box_annotator = bba, verbose = False, conf = True, conf_level = 0.05):\n",
    "    \n",
    "    cont_img = np.ascontiguousarray(input_img, dtype=np.uint8)\n",
    "    results = model(cont_img, conf=conf_level, verbose = verbose)[0]\n",
    "    conf_array = np.array(results.boxes.conf.cpu())\n",
    "    conf_ls_str  = [str(round(x * 100) ) + '%' for x in conf_array]\n",
    "    tot_time = sum([x for x in results.speed.values()])\n",
    "    \n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "    annotated_image = bounding_box_annotator.annotate(\n",
    "        scene=input_img, detections=detections)\n",
    "    num_oysters = detections.xyxy.shape[0]\n",
    "    annotated_image = label_annotator.annotate(\n",
    "        scene=annotated_image, detections=detections, labels = conf_ls_str)\n",
    "    return(annotated_image, num_oysters, tot_time)\n",
    "\n",
    "\n",
    "def annotate_video(input_vid, out_path = '.', model_file = 'best.pt', im_width = 416, im_height = 416):\n",
    "    bba = sv.BoundingBoxAnnotator()\n",
    "    la = sv.LabelAnnotator()\n",
    "    model = YOLOv10(model_file)\n",
    "\n",
    "    container = av.open(input_vid)\n",
    "    stream_vid = container.streams.video[0]\n",
    "    fname = input_vid.rsplit('/', 1)[-1]\n",
    "    per_index = fname.index('.')\n",
    "    out_path = f'{out_path}/{fname[:per_index]}_annotated.mp4'\n",
    "    outp = av.open(out_path, 'w')\n",
    "    codec_name = stream_vid.codec_context.name\n",
    "    fps = stream_vid.codec_context.rate\n",
    "    output_stream = outp.add_stream(codec_name, str(fps))\n",
    "    output_stream.width = im_width\n",
    "    output_stream.height = im_height\n",
    "    output_stream.pix_fmt = stream_vid.codec_context.pix_fmt\n",
    "    for index, frame in enumerate(container.decode(stream_vid)):\n",
    "        pil_img = frame.to_image()\n",
    "        np_img = np.array(pil_img)\n",
    "        np_img_resize = cv2.resize(np_img, (im_width, im_height))\n",
    "        np_rot = np_img_resize[:, :, ::-1]\n",
    "        small_pil_img = Image.fromarray(np_rot)\n",
    "        np_image_2 = np.array(small_pil_img)\n",
    "        an_mg, _, _2 = annotate_image(np_image_2, label_annotator = la, bounding_box_annotator=bba, model_pred = model, verbose = False)\n",
    "        frame_out = av.VideoFrame.from_ndarray(an_mg, format='bgr24')\n",
    "        pkt = output_stream.encode(frame_out)\n",
    "        outp.mux(pkt)\n",
    "    container.close()\n",
    "    outp.close()\n",
    "\n",
    "    print(f'Annotated video has been saved as {out_path}')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4015dd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_main = 'test_4'\n",
    "cur_name = 'ab'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2dbfd461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'1': 1}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_conn = pymysql.connect(\n",
    "    user=\"root\",\n",
    "    password=\"dbuserdbuser\",\n",
    "    host=\"localhost\",\n",
    "    port=3306,\n",
    "    database=db_main,\n",
    "    cursorclass=pymysql.cursors.DictCursor,\n",
    "    autocommit=True)\n",
    "\n",
    "cur = sql_conn.cursor()\n",
    "res = cur.execute(\"SELECT 1\")\n",
    "res = cur.fetchall()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "650cb013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Integrity Violated: Duplicate User with ab\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_user(name, password):\n",
    "    '''\n",
    "    Returns: 1 if query is successful, 0 if not\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        res = cur.execute(f\"INSERT INTO people (Username, Password, Time_Created) VALUES ('{name}', '{password}', CURRENT_TIMESTAMP );\")\n",
    "    except IntegrityError:\n",
    "        print(f\"Data Integrity Violated: Duplicate User with {name}\")\n",
    "        res = 0\n",
    "    return res\n",
    "add_user(cur_name, '123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9327bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ext(fpath):\n",
    "    fname = fpath.rsplit('/', 1)[-1]\n",
    "    per_index = fname.index('.')\n",
    "    ext = fname[per_index + 1:].lower()\n",
    "    return ext\n",
    "\n",
    "def get_id_fname(f_out, fpath, id):\n",
    "    fname = fpath.rsplit('/', 1)[-1]\n",
    "    per_index = fname.index('.')\n",
    "    ext = fname[per_index + 1:].lower()\n",
    "    return f\"{f_out}/{fname[:per_index]}-{id}.{ext}\"\n",
    "\n",
    "def get_REPLACE_ID(column_id = 'Raw_File_ID', table='raw_files', column_rep='Filepath'):\n",
    "    cur.execute(f\"\"\"SELECT {column_id} from {table} where {column_rep} = 'REPLACE'\"\"\")\n",
    "    id = cur.fetchall()[-1][column_id]\n",
    "    return id\n",
    "\n",
    "def get_match(pattern, string):\n",
    "    matches = re.search(pattern, string)\n",
    "    if matches:\n",
    "\n",
    "        print(matches.group(1))\n",
    "        return(matches.group(1))\n",
    "    else:\n",
    "        raise ValueError(f'Improper string exported, couldn\\'t find {pattern} in the given text')\n",
    "\n",
    "def delete_folder(name, base = \".\"):\n",
    "    fpath = os.path.join(base, name)\n",
    "    if os.path.exists(fpath):\n",
    "        for item in os.listdir(fpath):\n",
    "            new_path = os.path.join(fpath, item)\n",
    "            if os.path.isfile(new_path):\n",
    "                os.remove(new_path)\n",
    "            elif os.path.isdir(new_path):\n",
    "                delete_folder(item, fpath)\n",
    "        os.rmdir(fpath)\n",
    "\n",
    "def make_folder(fpath, overwrite = False):\n",
    "    delete_folder(fpath, '.') if overwrite else None\n",
    "    if os.path.exists(fpath):\n",
    "        \n",
    "        print(f\"{fpath} already exists\")\n",
    "    else:\n",
    "        os.mkdir(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b79cee66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already exists\n",
      "Files/Video_raw already exists\n",
      "Files/Video_ann already exists\n",
      "Files/Image_raw already exists\n",
      "Files/Image_ann already exists\n",
      "Files/Model already exists\n"
     ]
    }
   ],
   "source": [
    "make_folder('Files')\n",
    "make_folder('Files/Video_raw')\n",
    "make_folder('Files/Video_ann')\n",
    "make_folder('Files/Image_raw')\n",
    "make_folder('Files/Image_ann')\n",
    "make_folder('Files/Model')\n",
    "\n",
    "\n",
    "def add_photo(name, fpath, notes = '', f_out = './Files/Image_raw'):\n",
    "    '''\n",
    "    Returns: Index of added photo if successful, 0 if not\n",
    "    '''\n",
    "\n",
    "    im = Image.open(fpath)\n",
    "    width = im.size[0]\n",
    "    height = im.size[1]\n",
    "    fsize = os.stat(fpath).st_size\n",
    "    ext = get_ext(fpath)\n",
    "\n",
    "    cur.execute(f\"INSERT INTO raw_files (Username, Filepath, Size, Type, Extension, Notes, Width, Height, Time_Uploaded) VALUES ('{name}', 'REPLACE', {fsize}, 'Image', '{ext}', '{notes}', {width}, {height}, CURRENT_TIMESTAMP);\")\n",
    "    id = get_REPLACE_ID()\n",
    "    f_id_name = get_id_fname(f_out, fpath, id)\n",
    "    im.save(f_id_name)\n",
    "    cur.execute(f\"UPDATE raw_files SET Filepath = '{f_id_name}' WHERE Raw_File_ID = {id};\")\n",
    "    return id\n",
    "\n",
    "SOME_IMAGE_PATH = \"/mnt/linuxlab/home/mstaus1/Desktop/Shellfish_project_2024/Jupyter_local_code/problem_photo.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "id_raw_photo = add_photo(cur_name, fpath = SOME_IMAGE_PATH, notes = 'from HPC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a12356f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def add_video(name, fpath, notes = '', f_out = './Files/Video_raw'):\n",
    "    '''\n",
    "    Returns: Index of added video if successful, 0 if not\n",
    "    '''\n",
    "    cap = cv2.VideoCapture(fpath)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fsize = os.stat(fpath).st_size\n",
    "    ext = get_ext(fpath)\n",
    "    \n",
    "    cur.execute(f\"INSERT INTO raw_files (Username, Filepath, Size, Type, Extension, Notes, Width, Height, Time_Uploaded) VALUES ('{name}', 'REPLACE', {fsize}, 'Video', '{ext}', '{notes}', {width}, {height}, CURRENT_TIMESTAMP);\")\n",
    "    id = get_REPLACE_ID()\n",
    "    f_id_name = get_id_fname(f_out, fpath, id)\n",
    "    sh.copyfile(fpath, f_id_name)\n",
    "\n",
    "    cur.execute(f\"UPDATE raw_files SET Filepath = '{f_id_name}' WHERE Raw_File_ID = {id};\")\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    color_order = 'RGB' # FIXME - cant figure out how to extract from cv2 object\n",
    "\n",
    "    cur.execute(f\"INSERT INTO videos (Raw_File_ID, FPS, Color_Order) VALUES ('{id}', '{fps}', '{color_order}');\")\n",
    "\n",
    "    return id\n",
    "\n",
    "SOME_VIDEO_PATH = \"/mnt/linuxlab/home/mstaus1/Desktop/Shellfish_project_2024/Jupyter_local_code/GOPR1077.MP4\"\n",
    "id_raw_video = add_video(cur_name, SOME_VIDEO_PATH, notes='on new computer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56de2ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files/Roboflow already exists\n",
      "Rvk9Clz4ote58KBvCfU3\n",
      "curvy-oysters\n",
      "oysters-cjt7n\n",
      "19\n",
      "yolov8\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.1.34, to fix: `pip install ultralytics==8.0.196`\n",
      "./Files/Weights already exists\n",
      "<roboflow.core.dataset.Dataset object at 0x7f4aa0e9cd00>\n"
     ]
    }
   ],
   "source": [
    "make_folder('Files/Roboflow')\n",
    "        \n",
    "\n",
    "def add_roboflow(name, export_string, f_out = './Files/Roboflow', f_weights = \"./Files/Weights\"):\n",
    "    \n",
    "    '''\n",
    "    Returns: Index of added roboflow if successful, 0 if not\n",
    "    '''\n",
    "    pattern_api = r'api_key\\s*=\\s*\"([^\"]+)\"'\n",
    "    api_key_lab = get_match(pattern_api, export_string)\n",
    "\n",
    "    pattern_workspace = r'rf\\.workspace\\(\"([^\"]+)\"\\)'\n",
    "    workspace_lab = get_match(pattern_workspace, export_string)\n",
    "\n",
    "    pattern_project = r'project\\(\"([^\"]+)\"\\)'\n",
    "    project_lab = get_match(pattern_project, export_string)\n",
    "\n",
    "    pattern_version = r'version\\((\\d+)\\)'\n",
    "    version_lab = get_match(pattern_version, export_string)\n",
    "\n",
    "    pattern_download = r'\\bdownload\\(\"([^\"]+)\"\\)'\n",
    "    download_lab = get_match(pattern_download, export_string)\n",
    "\n",
    "    folder_roboflow = f\"{f_out}/{workspace_lab}_{project_lab}_{version_lab}_{download_lab}\"\n",
    "\n",
    "    # if not os.path.exists(folder_roboflow):\n",
    "    rf = Roboflow(api_key = api_key_lab)\n",
    "    project = rf.workspace(workspace_lab).project(project_lab)\n",
    "    version = project.version(version_lab)\n",
    "    dat = version.download(download_lab, location = folder_roboflow)\n",
    "    \n",
    "    fpath = os.path.join(folder_roboflow, 'data.yaml')\n",
    "\n",
    "    with open(fpath) as f1:\n",
    "        lines = f1.readlines()\n",
    "    with open(fpath, 'w') as f2:\n",
    "        f2.writelines(lines[:-4])\n",
    "        f2.write(\"test: ../test/images\\ntrain: ../train/images\\nval: ../valid/images\\n\\n\")\n",
    "\n",
    "    make_folder(f_weights)\n",
    "    prefix = \"https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10\"\n",
    "    versions = ['n', 's', 'm', 'b', 'x', 'l']\n",
    "    suffix = \".pt\"\n",
    "    for ver in versions:\n",
    "        web_path = prefix + ver + suffix\n",
    "        computer_path = os.path.join(f_weights, 'yolov10' + ver + suffix)\n",
    "        if not os.path.exists(computer_path):\n",
    "            wget.download(web_path, out = f_weights)\n",
    "    cur.execute(f\"INSERT INTO roboflow (Api_Key, Workspace, Project, Version, Download, Dataset_Location, Username, Timestamp) VALUES ('REPLACE', '{workspace_lab}', '{project_lab}', '{version_lab}', '{download_lab}', '{folder_roboflow}', '{name}', CURRENT_TIMESTAMP);\")\n",
    "    \n",
    "    id = get_REPLACE_ID('Roboflow_ID', 'roboflow', 'Api_Key')\n",
    "    \n",
    "    cur.execute(f\"UPDATE roboflow SET Api_Key = '{api_key_lab}' WHERE Roboflow_ID = {id};\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    return id\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "id_rob = add_roboflow(cur_name, \\\n",
    "\"\"\"\n",
    "rf = Roboflow(api_key=\"Rvk9Clz4ote58KBvCfU3\")\n",
    "project = rf.workspace(\"curvy-oysters\").project(\"oysters-cjt7n\")\n",
    "dataset = project.version(19).download(\"yolov8\")\n",
    "\n",
    "\"\"\" )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "43f6f22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.40 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.9.7 torch-1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 4080, 16071MiB)\n",
      "WARNING âš ï¸ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=./Files/Weights/yolov10n.pt, data=/mnt/linuxlab/home/mstaus1/Desktop/Shellfish_project_2024/sql/Files/Roboflow/curvy-oysters_oysters-cjt7n_19_yolov8/data.yaml, epochs=10, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    861718  ultralytics.nn.modules.head.v10Detect        [1, [64, 128, 256]]           \n",
      "YOLOv10n summary: 385 layers, 2707430 parameters, 2707414 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/linuxlab/home/mstaus1/Desktop/Shellfish_project_2024/sql/Fi\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/linuxlab/home/mstaus1/Desktop/Shellfish_project_2024/sql/File\u001b[0m\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "       1/10      6.63G      1.721      2.169      1.795      1.503      3.092   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m/mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages/ultralytics/utils/ops.py:862: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  index = index // nc\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         92       1501      0.316      0.118      0.111      0.045\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "       2/10      6.53G      1.704       1.73      1.699      1.592      2.401   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m/mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages/ultralytics/utils/ops.py:862: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  index = index // nc\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         92       1501      0.336      0.408      0.289      0.132\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "       3/10      6.49G      1.665      1.644      1.671      1.611      2.115   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m/mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages/ultralytics/utils/ops.py:862: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  index = index // nc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         92       1501      0.331       0.37      0.265      0.122\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "       4/10      6.15G      1.646       1.58      1.652      1.616      1.968   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m/mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages/ultralytics/utils/ops.py:862: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  index = index // nc\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         92       1501       0.42      0.421      0.363       0.16\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "       5/10       6.3G      1.634      1.529      1.638      1.615      1.868   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m/mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages/ultralytics/utils/ops.py:862: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  index = index // nc\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         92       1501      0.374      0.319      0.265      0.132\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "       6/10       6.5G      1.575      1.432      1.583       1.58      1.731   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m/mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages/ultralytics/utils/ops.py:862: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  index = index // nc\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         92       1501      0.507      0.471      0.473      0.239\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "       7/10      6.33G      1.542      1.406      1.557      1.549      1.689   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m/mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages/ultralytics/utils/ops.py:862: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  index = index // nc\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         92       1501      0.513      0.494      0.488      0.256\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "       8/10      6.39G      1.517      1.332      1.537      1.526      1.612   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m/mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages/ultralytics/utils/ops.py:862: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  index = index // nc\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         92       1501      0.505      0.476      0.477      0.266\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "       9/10      6.25G      1.445      1.527      1.476      1.461      1.536   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m/mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages/ultralytics/utils/ops.py:862: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  index = index // nc\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         92       1501       0.58      0.423      0.476      0.262\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "      10/10      6.17G      1.428      1.196      1.469      1.455      1.452   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m/mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages/ultralytics/utils/ops.py:862: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  index = index // nc\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         92       1501      0.602      0.512      0.562       0.32\n",
      "\n",
      "10 epochs completed in 0.039 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 5.8MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 5.8MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.34 ðŸš€ Python-3.9.7 torch-1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 4080, 16071MiB)\n",
      "YOLOv10n summary (fused): 285 layers, 2694806 parameters, 0 gradients, 8.2 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m/mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages/ultralytics/utils/ops.py:862: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  index = index // nc\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         92       1501      0.602      0.512      0.562       0.32\n",
      "Speed: 0.1ms preprocess, 1.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "def add_model(roboflow_ID, f_out = \"./Files/Model\", weights_path = \"./Files/Weights/yolov10n.pt\", epochs = 10, batch = 32):\n",
    "#     make_folder(tmp_path)\n",
    "    cur.execute(f\"SELECT * FROM roboflow WHERE Roboflow_ID = {roboflow_ID}\")\n",
    "    res = cur.fetchall()[-1]\n",
    "    pt = os.path.join(os.getcwd(), res['Dataset_Location'][len('.\\\\'):], 'data.yaml')\n",
    "    samp_photo = os.path.join(res['Dataset_Location'], 'test/images')\n",
    "    pt_rep = pt.replace('\\\\', '/')\n",
    "    !yolo task=detect mode=train epochs={epochs} batch={batch} plots=False model={weights_path} data={pt_rep}\n",
    "    \n",
    "    \n",
    "    first_photo = os.listdir(samp_photo)[0]\n",
    "    im = Image.open(os.path.join(samp_photo, first_photo))\n",
    "    width = im.size[0]\n",
    "    height = im.size[1]\n",
    "                                                               \n",
    "    cur.execute(f\"\"\"INSERT INTO models (Timestamp_Created, Model_Points_Path, Version, \n",
    "                Hyperparams, Model_Type, Width_Training_Images, Height_Training_Images, Roboflow_ID) values\n",
    "                (CURRENT_TIMESTAMP, 'REPLACE', 10, 'epochs = {epochs} batch = {batch}', 'YOLO', {width}, {height}, {roboflow_ID})\n",
    "                \"\"\")\n",
    "    \n",
    "    id_mod = get_REPLACE_ID(column_id = 'Model_ID', table='models', column_rep='Model_Points_Path')\n",
    "    model_path = f'./Files/Model/{id_mod}.pt'\n",
    "    os.rename('./runs/detect/train/weights/best.pt', model_path)\n",
    "    \n",
    "    cur.execute(f\"UPDATE models SET Model_Points_Path = '{model_path}' WHERE Model_ID = {id_mod};\")\n",
    "\n",
    "    delete_folder('runs')\n",
    "#     delete_folder(tmp_path)\n",
    "    return id_mod\n",
    "\n",
    "id_mod = add_model(id_rob,epochs=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6a917f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Files/Image_ann/problem_photo-9-14.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def ann_img(Raw_File_ID, Model_ID, notes = '', f_out = './Files/Image_ann'):\n",
    "    try:\n",
    "        cur.execute(f\"SELECT * FROM raw_files WHERE Raw_File_ID = {Raw_File_ID}\")\n",
    "        cur_photo = cur.fetchall()[-1]\n",
    "\n",
    "        cur.execute(f\"SELECT * FROM models WHERE Model_ID = {Model_ID}\")\n",
    "        cur_model = cur.fetchall()[-1]\n",
    "\n",
    "        #     print(cur_photo, cur_model)\n",
    "\n",
    "\n",
    "        im = Image.open(cur_photo['Filepath'])\n",
    "        np_img = np.array(im)\n",
    "        model = YOLOv10(cur_model['Model_Points_Path'])\n",
    "#         print(model)\n",
    "        annot, num_oysters, tot_time = annotate_image(np_img, model)\n",
    "\n",
    "        cur.execute(f\"INSERT INTO annotated_files (Raw_File_ID, Model_ID, Annotated_Filepath, Time_to_Annotate, Notes, Timestamp) VALUES ('{Raw_File_ID}', '{Model_ID}', 'REPLACE', '{tot_time}', '{notes}', CURRENT_TIMESTAMP);\")\n",
    "        id = get_REPLACE_ID(column_id = 'Ann_File_ID', table='annotated_files', column_rep='Annotated_Filepath')\n",
    "        f_id_name = get_id_fname(f_out, cur_photo['Filepath'], id)\n",
    "        print(f_id_name)\n",
    "        im_f = Image.fromarray(annot)\n",
    "        im_f.save(f_id_name)\n",
    "        cur.execute(f\"UPDATE annotated_files SET Annotated_Filepath = '{f_id_name}' WHERE Ann_File_ID = {id};\")\n",
    "        cur.execute(f\"INSERT INTO annotated_photos (Ann_File_ID, Number_of_Oysters) VALUES ({id}, {num_oysters})\")\n",
    "        \n",
    "        return id\n",
    "    except IntegrityError:\n",
    "        cur.execute(f\"SELECT Ann_File_ID FROM annotated_files WHERE Raw_File_ID = {Raw_File_ID} AND Model_ID = {Model_ID}\")\n",
    "        return(cur.fetchall()[-1]['Ann_File_ID'])\n",
    "        \n",
    "\n",
    "ann_photo_id = ann_img(id_raw_photo, id_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebaa48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def annotate_video(input_vid, out_path = '.', model_file = 'best.pt', im_width = 416, im_height = 416):\n",
    "    tot_oysters = 0\n",
    "    tot_frame = 0\n",
    "    \n",
    "    \n",
    "    bba = sv.BoundingBoxAnnotator()\n",
    "    la = sv.LabelAnnotator()\n",
    "    model = YOLOv10(model_file)\n",
    "\n",
    "    container = av.open(input_vid)\n",
    "    stream_vid = container.streams.video[0]\n",
    "    fname = input_vid.rsplit('/', 1)[-1]\n",
    "    per_index = fname.index('.')\n",
    "    out_path = os.path.join(out_path, f'{fname[:per_index]}_annotated.mp4')\n",
    "    outp = av.open(out_path, 'w')\n",
    "    codec_name = stream_vid.codec_context.name\n",
    "    fps = stream_vid.codec_context.rate\n",
    "    output_stream = outp.add_stream(codec_name, str(fps))\n",
    "    output_stream.width = im_width\n",
    "    output_stream.height = im_height\n",
    "    output_stream.pix_fmt = stream_vid.codec_context.pix_fmt\n",
    "    start = time()\n",
    "    for index, frame in enumerate(container.decode(stream_vid)):\n",
    "        pil_img = frame.to_image()\n",
    "        np_img = np.array(pil_img)\n",
    "        np_img_resize = cv2.resize(np_img, (im_width, im_height))\n",
    "        np_rot = np_img_resize[:, :, ::-1]\n",
    "        small_pil_img = Image.fromarray(np_rot)\n",
    "        np_image_2 = np.array(small_pil_img)\n",
    "        an_mg, num_oysters, _ = annotate_image(np_image_2, model)\n",
    "        tot_oysters += num_oysters\n",
    "        frame_out = av.VideoFrame.from_ndarray(an_mg, format='bgr24')\n",
    "        pkt = output_stream.encode(frame_out)\n",
    "        outp.mux(pkt)\n",
    "    end = time()\n",
    "    container.close()\n",
    "    outp.close()\n",
    "\n",
    "    print(f'Annotated video has been saved as {out_path}')\n",
    "    return tot_oysters / index, end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_video(Raw_File_ID, Model_ID, notes = '', f_out = './Files/Video_ann'):\n",
    "    try:\n",
    "        cur.execute(f\"SELECT * FROM raw_files WHERE Raw_File_ID = {Raw_File_ID}\")\n",
    "        cur_photo = cur.fetchall()[-1]\n",
    "\n",
    "        cur.execute(f\"SELECT * FROM models WHERE Model_ID = {Model_ID}\")\n",
    "        cur_model = cur.fetchall()[-1]\n",
    "        \n",
    "        avg_oysters, annotate_video()\n",
    "        \n",
    "        \n",
    "    except IntegrityError:\n",
    "        cur.execute(f\"SELECT Ann_File_ID FROM annotated_files WHERE Raw_File_ID = {Raw_File_ID} AND Model_ID = {Model_ID}\")\n",
    "        return(cur.fetchall()[-1]['Ann_File_ID'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5aba45b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Files/tmp already exists\n",
      "['yolov8n.pt', 'base_sql.ipynb', 'runs', 'oyster_project.ddl', '.ipynb_checkpoints', 'Files']\n"
     ]
    }
   ],
   "source": [
    "# make_folder(\"./Files/tmp\")\n",
    "# print(os.listdir('.'))\n",
    "# os.rename('./runs/detect/train/weights/best.pt', './Files/Model/f1/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02ffb203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "print(id_raw_photo)\n",
    "print(id_raw_video)\n",
    "print(id_rob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25291475",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_folder('runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a157edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_folder('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c68e964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
