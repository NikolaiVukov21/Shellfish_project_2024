{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d424f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q sql av pillow pandas sqlalchemy ipython-sql pymysql roboflow git+https://github.com/THU-MIG/yolov10.git supervision huggingface_hub bottleneck==1.3.6 numexpr==2.8.4 wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9de8481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from pymysql.err import IntegrityError, OperationalError\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "import cv2\n",
    "import av\n",
    "from PIL import Image\n",
    "import shutil as sh\n",
    "import re\n",
    "from roboflow import Roboflow\n",
    "import cv2\n",
    "from ultralytics import YOLOv10\n",
    "import wget\n",
    "from time import time\n",
    "\n",
    "# model_path = '../Jupyter_local_code/best.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8310e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = YOLOv10(model_path)\n",
    "bba = sv.BoxCornerAnnotator()\n",
    "la = sv.LabelAnnotator(text_scale = 0.4, text_padding = 1)\n",
    "\n",
    "def annotate_image(input_img, model, label_annotator = la, bounding_box_annotator = bba, verbose = False, conf = True, conf_level = 0.05):\n",
    "    \n",
    "    cont_img = np.ascontiguousarray(input_img, dtype=np.uint8)\n",
    "    results = model(cont_img, conf=conf_level, verbose = verbose)[0]\n",
    "    conf_array = np.array(results.boxes.conf.cpu())\n",
    "    conf_ls_str  = [str(round(x * 100) ) + '%' for x in conf_array]\n",
    "    tot_time = sum([x for x in results.speed.values()])\n",
    "    \n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "    annotated_image = bounding_box_annotator.annotate(\n",
    "        scene=input_img, detections=detections)\n",
    "    num_oysters = detections.xyxy.shape[0]\n",
    "    annotated_image = label_annotator.annotate(\n",
    "        scene=annotated_image, detections=detections, labels = conf_ls_str)\n",
    "    return(annotated_image, num_oysters, tot_time, detections)\n",
    "\n",
    "\n",
    "def annotate_video(input_vid, model, out_location = '.', im_width = 416, im_height = 416, conf_level = 0.3):\n",
    "    tot_oysters = 0\n",
    "    tot_frame = 0\n",
    "    \n",
    "    bba = sv.BoundingBoxAnnotator()\n",
    "    la = sv.LabelAnnotator()\n",
    "\n",
    "    container = av.open(input_vid)\n",
    "    stream_vid = container.streams.video[0]\n",
    "    fname = input_vid.rsplit('/', 1)[-1]\n",
    "    per_index = fname.index('.')\n",
    "    out_path = os.path.join(out_location, f'{fname[:per_index]}_annotated.mp4')\n",
    "    outp = av.open(out_path, 'w')\n",
    "    codec_name = stream_vid.codec_context.name\n",
    "    fps = stream_vid.codec_context.rate\n",
    "    output_stream = outp.add_stream(codec_name, str(fps))\n",
    "    output_stream.width = im_width\n",
    "    output_stream.height = im_height\n",
    "    output_stream.pix_fmt = stream_vid.codec_context.pix_fmt\n",
    "    start = time()\n",
    "    for index, frame in enumerate(container.decode(stream_vid)):\n",
    "        pil_img = frame.to_image()\n",
    "        np_img = np.array(pil_img)\n",
    "        np_img_resize = cv2.resize(np_img, (im_width, im_height))\n",
    "        np_rot = np_img_resize[:, :, ::-1]\n",
    "        small_pil_img = Image.fromarray(np_rot)\n",
    "        np_image_2 = np.array(small_pil_img)\n",
    "        an_mg, num_oysters, _, _2z = annotate_image(np_image_2, model, conf_level = conf_level)\n",
    "        tot_oysters += num_oysters\n",
    "        frame_out = av.VideoFrame.from_ndarray(an_mg, format='bgr24')\n",
    "        pkt = output_stream.encode(frame_out)\n",
    "        outp.mux(pkt)\n",
    "    end = time()\n",
    "    net_time = end - start\n",
    "    container.close()\n",
    "    outp.close()\n",
    "    ann_rate = (index / fps) / net_time # ratio of time to annotate versus length of video\n",
    "#     print(f'Annotated video has been saved as {out_path}')\n",
    "    return tot_oysters / index, net_time, out_path, ann_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4015dd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_main = 'test_4'\n",
    "cur_name = 'ab'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dbfd461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'1': 1}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_conn = pymysql.connect(\n",
    "    user=\"root\",\n",
    "    password=\"dbuserdbuser\",\n",
    "    host=\"localhost\",\n",
    "    port=3306,\n",
    "    database=db_main,\n",
    "    cursorclass=pymysql.cursors.DictCursor,\n",
    "    autocommit=True)\n",
    "\n",
    "cur = sql_conn.cursor()\n",
    "res = cur.execute(\"SELECT 1\")\n",
    "res = cur.fetchall()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "650cb013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Integrity Violated: Duplicate User with ab\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ab'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_user(name, password):\n",
    "    '''\n",
    "    Returns: name if query is successful, 0 if not\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        cur.execute(f\"INSERT INTO people (Username, Password, Time_Created) VALUES ('{name}', '{password}', CURRENT_TIMESTAMP );\")\n",
    "    except IntegrityError:\n",
    "        print(f\"Data Integrity Violated: Duplicate User with {name}\")\n",
    "    return name\n",
    "add_user(cur_name, '123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9327bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ext(fpath):\n",
    "    fname = fpath.rsplit('/', 1)[-1]\n",
    "    per_index = fname.index('.')\n",
    "    ext = fname[per_index + 1:].lower()\n",
    "    return ext\n",
    "\n",
    "def get_id_fname(f_out, fpath, id):\n",
    "    fname = fpath.rsplit('/', 1)[-1]\n",
    "    per_index = fname.index('.')\n",
    "    ext = fname[per_index + 1:].lower()\n",
    "    return f\"{f_out}/{fname[:per_index]}-{id}.{ext}\"\n",
    "\n",
    "def get_REPLACE_ID(column_id = 'Raw_File_ID', table='raw_files', column_rep='Filepath'):\n",
    "    cur.execute(f\"\"\"SELECT {column_id} from {table} where {column_rep} = 'REPLACE'\"\"\")\n",
    "    id = cur.fetchall()[-1][column_id]\n",
    "    return id\n",
    "\n",
    "def get_match(pattern, string):\n",
    "    matches = re.search(pattern, string)\n",
    "    if matches:\n",
    "\n",
    "        print(matches.group(1))\n",
    "        return(matches.group(1))\n",
    "    else:\n",
    "        raise ValueError(f'Improper string exported, couldn\\'t find {pattern} in the given text')\n",
    "\n",
    "def delete_folder(name, base = \".\"):\n",
    "    fpath = os.path.join(base, name)\n",
    "    if os.path.exists(fpath):\n",
    "        for item in os.listdir(fpath):\n",
    "            new_path = os.path.join(fpath, item)\n",
    "            if os.path.isfile(new_path):\n",
    "                os.remove(new_path)\n",
    "            elif os.path.isdir(new_path):\n",
    "                delete_folder(item, fpath)\n",
    "        os.rmdir(fpath)\n",
    "\n",
    "def make_folder(fpath, overwrite = False):\n",
    "    delete_folder(fpath, '.') if overwrite else None\n",
    "    if os.path.exists(fpath):\n",
    "        \n",
    "        print(f\"{fpath} already exists\")\n",
    "    else:\n",
    "        os.mkdir(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b79cee66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already exists\n",
      "Files/Video_raw already exists\n",
      "Files/Video_ann already exists\n",
      "Files/Image_raw already exists\n",
      "Files/Image_ann already exists\n",
      "Files/Model already exists\n"
     ]
    }
   ],
   "source": [
    "make_folder('Files')\n",
    "make_folder('Files/Video_raw')\n",
    "make_folder('Files/Video_ann')\n",
    "make_folder('Files/Image_raw')\n",
    "make_folder('Files/Image_ann')\n",
    "make_folder('Files/Model')\n",
    "\n",
    "\n",
    "def add_photo(name, fpath, notes = '', f_out = './Files/Image_raw'):\n",
    "    '''\n",
    "    Returns: Index of added photo if successful, 0 if not\n",
    "    '''\n",
    "\n",
    "    im = Image.open(fpath)\n",
    "    width = im.size[0]\n",
    "    height = im.size[1]\n",
    "    fsize = os.stat(fpath).st_size\n",
    "    ext = get_ext(fpath)\n",
    "\n",
    "    cur.execute(f\"INSERT INTO raw_files (Username, Filepath, Size, Type, Extension, Notes, Width, Height, Time_Uploaded) VALUES ('{name}', 'REPLACE', {fsize}, 'Image', '{ext}', '{notes}', {width}, {height}, CURRENT_TIMESTAMP);\")\n",
    "    id = get_REPLACE_ID()\n",
    "    f_id_name = get_id_fname(f_out, fpath, id)\n",
    "    im.save(f_id_name)\n",
    "    cur.execute(f\"UPDATE raw_files SET Filepath = '{f_id_name}' WHERE Raw_File_ID = {id};\")\n",
    "    return id\n",
    "\n",
    "SOME_IMAGE_PATH = \"/mnt/linuxlab/home/mstaus1/Desktop/Shellfish_project_2024/Jupyter_local_code/problem_photo.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "id_raw_photo = add_photo(cur_name, fpath = SOME_IMAGE_PATH, notes = 'from HPC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a12356f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def add_video(name, fpath, notes = '', f_out = './Files/Video_raw'):\n",
    "    '''\n",
    "    Returns: Index of added video if successful, 0 if not\n",
    "    '''\n",
    "    cap = cv2.VideoCapture(fpath)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fsize = os.stat(fpath).st_size\n",
    "    ext = get_ext(fpath)\n",
    "    \n",
    "    cur.execute(f\"INSERT INTO raw_files (Username, Filepath, Size, Type, Extension, Notes, Width, Height, Time_Uploaded) VALUES ('{name}', 'REPLACE', {fsize}, 'Video', '{ext}', '{notes}', {width}, {height}, CURRENT_TIMESTAMP);\")\n",
    "    id = get_REPLACE_ID()\n",
    "    f_id_name = get_id_fname(f_out, fpath, id)\n",
    "    sh.copyfile(fpath, f_id_name)\n",
    "\n",
    "    cur.execute(f\"UPDATE raw_files SET Filepath = '{f_id_name}' WHERE Raw_File_ID = {id};\")\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    color_order = 'RGB' # FIXME - cant figure out how to extract from cv2 object\n",
    "\n",
    "    cur.execute(f\"INSERT INTO videos (Raw_File_ID, FPS, Color_Order) VALUES ('{id}', '{fps}', '{color_order}');\")\n",
    "\n",
    "    return id\n",
    "\n",
    "SOME_VIDEO_PATH = \"/mnt/linuxlab/home/mstaus1/Desktop/Shellfish_project_2024/Jupyter_local_code/GOPR1077.MP4\"\n",
    "id_raw_video = add_video(cur_name, SOME_VIDEO_PATH, notes='on new computer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56de2ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files/Roboflow already exists\n",
      "Rvk9Clz4ote58KBvCfU3\n",
      "curvy-oysters\n",
      "oysters-cjt7n\n",
      "19\n",
      "yolov8\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.1.34, to fix: `pip install ultralytics==8.0.196`\n",
      "./Files/Weights already exists\n"
     ]
    }
   ],
   "source": [
    "make_folder('Files/Roboflow')\n",
    "        \n",
    "\n",
    "def add_roboflow(name, export_string, f_out = './Files/Roboflow', f_weights = \"./Files/Weights\"):\n",
    "    \n",
    "    '''\n",
    "    Returns: Index of added roboflow if successful, 0 if not\n",
    "    '''\n",
    "    pattern_api = r'api_key\\s*=\\s*\"([^\"]+)\"'\n",
    "    api_key_lab = get_match(pattern_api, export_string)\n",
    "\n",
    "    pattern_workspace = r'rf\\.workspace\\(\"([^\"]+)\"\\)'\n",
    "    workspace_lab = get_match(pattern_workspace, export_string)\n",
    "\n",
    "    pattern_project = r'project\\(\"([^\"]+)\"\\)'\n",
    "    project_lab = get_match(pattern_project, export_string)\n",
    "\n",
    "    pattern_version = r'version\\((\\d+)\\)'\n",
    "    version_lab = get_match(pattern_version, export_string)\n",
    "\n",
    "    pattern_download = r'\\bdownload\\(\"([^\"]+)\"\\)'\n",
    "    download_lab = get_match(pattern_download, export_string)\n",
    "\n",
    "    folder_roboflow = f\"{f_out}/{workspace_lab}_{project_lab}_{version_lab}_{download_lab}\"\n",
    "\n",
    "    # if not os.path.exists(folder_roboflow):\n",
    "    rf = Roboflow(api_key = api_key_lab)\n",
    "    project = rf.workspace(workspace_lab).project(project_lab)\n",
    "    version = project.version(version_lab)\n",
    "    dat = version.download(download_lab, location = folder_roboflow)\n",
    "    \n",
    "    fpath = os.path.join(folder_roboflow, 'data.yaml')\n",
    "\n",
    "    with open(fpath) as f1:\n",
    "        lines = f1.readlines()\n",
    "    with open(fpath, 'w') as f2:\n",
    "        f2.writelines(lines[:-4])\n",
    "        f2.write(\"test: ../test/images\\ntrain: ../train/images\\nval: ../valid/images\\n\\n\")\n",
    "\n",
    "    make_folder(f_weights)\n",
    "    prefix = \"https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10\"\n",
    "    versions = ['n', 's', 'm', 'b', 'x', 'l']\n",
    "    suffix = \".pt\"\n",
    "    for ver in versions:\n",
    "        web_path = prefix + ver + suffix\n",
    "        computer_path = os.path.join(f_weights, 'yolov10' + ver + suffix)\n",
    "        if not os.path.exists(computer_path):\n",
    "            wget.download(web_path, out = f_weights)\n",
    "    cur.execute(f\"INSERT INTO roboflow (Api_Key, Workspace, Project, Version, Download, Dataset_Location, Username, Timestamp) VALUES ('REPLACE', '{workspace_lab}', '{project_lab}', '{version_lab}', '{download_lab}', '{folder_roboflow}', '{name}', CURRENT_TIMESTAMP);\")\n",
    "    \n",
    "    id = get_REPLACE_ID('Roboflow_ID', 'roboflow', 'Api_Key')\n",
    "    \n",
    "    cur.execute(f\"UPDATE roboflow SET Api_Key = '{api_key_lab}' WHERE Roboflow_ID = {id};\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    return id\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "id_rob = add_roboflow(cur_name, \\\n",
    "\"\"\"\n",
    "rf = Roboflow(api_key=\"Rvk9Clz4ote58KBvCfU3\")\n",
    "project = rf.workspace(\"curvy-oysters\").project(\"oysters-cjt7n\")\n",
    "dataset = project.version(19).download(\"yolov8\")\n",
    "\n",
    "\"\"\" )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43f6f22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.41 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 🚀 Python-3.9.7 torch-1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 4080, 16071MiB)\n",
      "WARNING ⚠️ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=./Files/Weights/yolov10s.pt, data=/mnt/linuxlab/home/mstaus1/Desktop/Shellfish_project_2024/sql/Files/Roboflow/curvy-oysters_oysters-cjt7n_19_yolov8/data.yaml, epochs=1, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, val_period=1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train6\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1    137728  ultralytics.nn.modules.block.SCDown          [256, 512, 3, 2]              \n",
      "  8                  -1  1    958464  ultralytics.nn.modules.block.C2fCIB          [512, 512, 1, True, True]     \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.PSA             [512, 512]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 20                  -1  1     68864  ultralytics.nn.modules.block.SCDown          [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1089536  ultralytics.nn.modules.block.C2fCIB          [768, 512, 1, True, True]     \n",
      " 23        [16, 19, 22]  1   1639574  ultralytics.nn.modules.head.v10Detect        [1, [128, 256, 512]]          \n",
      "YOLOv10s summary: 402 layers, 8067126 parameters, 8067110 gradients, 24.8 GFLOPs\n",
      "\n",
      "Transferred 607/619 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train6', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/linuxlab/home/mstaus1/Desktop/Shellfish_project_2024/sql/Fi\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/linuxlab/home/mstaus1/Desktop/Shellfish_project_2024/sql/File\u001b[0m\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 99 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train6\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem     box_om     cls_om     dfl_om     box_oo     cls_oo     dfl_oo  Instances       Size\n",
      "        1/1      11.2G      1.659      1.705      1.671      1.596      2.458   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m/mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages/ultralytics/utils/ops.py:862: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  index = index // nc\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         92       1501      0.232      0.328      0.185     0.0729\n",
      "\n",
      "1 epochs completed in 0.014 hours.\n",
      "Optimizer stripped from runs/detect/train6/weights/last.pt, 16.5MB\n",
      "Optimizer stripped from runs/detect/train6/weights/best.pt, 16.5MB\n",
      "\n",
      "Validating runs/detect/train6/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.34 🚀 Python-3.9.7 torch-1.10.1+cu113 CUDA:0 (NVIDIA GeForce RTX 4080, 16071MiB)\n",
      "YOLOv10s summary (fused): 293 layers, 8035734 parameters, 0 gradients, 24.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m/mnt/linuxlab/home/mstaus1/anaconda3/lib/python3.9/site-packages/ultralytics/utils/ops.py:862: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  index = index // nc\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all         92       1501      0.232      0.331      0.185     0.0729\n",
      "Speed: 0.1ms preprocess, 2.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "def add_model(roboflow_ID, f_out = \"./Files/Model\", size_mod = 'n', weights_path = \"./Files/Weights/yolov10n.pt\", epochs = 10, batch = 32):\n",
    "#     make_folder(tmp_path)\n",
    "    weights_path = os.path.join(\"./Files/Weights\", f\"yolov10{size_mod}.pt\")\n",
    "    cur.execute(f\"SELECT * FROM roboflow WHERE Roboflow_ID = {roboflow_ID}\")\n",
    "    res = cur.fetchall()[-1]\n",
    "    pt = os.path.join(os.getcwd(), res['Dataset_Location'][len('.\\\\'):], 'data.yaml')\n",
    "    samp_photo = os.path.join(res['Dataset_Location'], 'test/images')\n",
    "    pt_rep = pt.replace('\\\\', '/')\n",
    "    !yolo task=detect mode=train epochs={epochs} batch={batch} plots=False model={weights_path} data={pt_rep}\n",
    "    \n",
    "    \n",
    "    first_photo = os.listdir(samp_photo)[0]\n",
    "    im = Image.open(os.path.join(samp_photo, first_photo))\n",
    "    width = im.size[0]\n",
    "    height = im.size[1]\n",
    "                                                               \n",
    "    cur.execute(f\"\"\"INSERT INTO models (Timestamp_Created, Model_Points_Path, Version, \n",
    "                Hyperparams, Epoch, Batch, Model_Type, Width_Training_Images, Height_Training_Images, \n",
    "                Size, Roboflow_ID) values (CURRENT_TIMESTAMP, 'REPLACE', 10, NULL, {epochs}, {batch}, \n",
    "                'YOLO', {width}, {height}, '{size_mod}', {roboflow_ID})\n",
    "                \"\"\")\n",
    "    \n",
    "    id_mod = get_REPLACE_ID(column_id = 'Model_ID', table='models', column_rep='Model_Points_Path')\n",
    "    model_path = f'./Files/Model/{id_mod}.pt'\n",
    "    os.rename('./runs/detect/train/weights/best.pt', model_path)\n",
    "    \n",
    "    cur.execute(f\"UPDATE models SET Model_Points_Path = '{model_path}' WHERE Model_ID = {id_mod};\")\n",
    "\n",
    "    delete_folder('runs')\n",
    "#     delete_folder(tmp_path)\n",
    "    return id_mod\n",
    "\n",
    "id_mod = add_model(id_rob,epochs=1, size_mod = 's')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a917f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ann_img(Raw_File_ID, Model_ID, threshold = 0.3, notes = '', f_out = './Files/Image_ann'):\n",
    "    try:\n",
    "        cur.execute(f\"SELECT * FROM raw_files WHERE Raw_File_ID = {Raw_File_ID}\")\n",
    "        cur_photo = cur.fetchall()[-1]\n",
    "\n",
    "        cur.execute(f\"SELECT * FROM models WHERE Model_ID = {Model_ID}\")\n",
    "        cur_model = cur.fetchall()[-1]\n",
    "\n",
    "        #     print(cur_photo, cur_model)\n",
    "\n",
    "\n",
    "        im = Image.open(cur_photo['Filepath'])\n",
    "        np_img = np.array(im)\n",
    "        model = YOLOv10(cur_model['Model_Points_Path'])\n",
    "#         print(model)\n",
    "        annot, num_oysters, tot_time, end_ann_data = annotate_image(np_img, model, conf_level = threshold)\n",
    "#         print(end_ann_data)\n",
    "        \n",
    "\n",
    "        cur.execute(f\"INSERT INTO annotated_files (Raw_File_ID, Model_ID, Annotated_Filepath, Time_to_Annotate, Confidence_Threshold, Notes, Timestamp) VALUES ('{Raw_File_ID}', '{Model_ID}', 'REPLACE', '{tot_time}', {threshold}, '{notes}', CURRENT_TIMESTAMP);\")\n",
    "        id = get_REPLACE_ID(column_id = 'Ann_File_ID', table='annotated_files', column_rep='Annotated_Filepath')\n",
    "        f_id_name = get_id_fname(f_out, cur_photo['Filepath'], id)\n",
    "#         print(f_id_name)\n",
    "        im_f = Image.fromarray(annot)\n",
    "        im_f.save(f_id_name)\n",
    "        \n",
    "                \n",
    "        cur.execute(f\"UPDATE annotated_files SET Annotated_Filepath = '{f_id_name}' WHERE Ann_File_ID = {id};\")\n",
    "        cur.execute(f\"INSERT INTO annotated_photos (Ann_File_ID, Number_of_Oysters) VALUES ({id}, {num_oysters})\")\n",
    "        \n",
    "        coord = end_ann_data.xyxy\n",
    "        conf = end_ann_data.confidence\n",
    "        names = end_ann_data.data['class_name']\n",
    "        class_num = end_ann_data.class_id\n",
    "        for idx in range(len(coord)):\n",
    "#             print('Here')\n",
    "            coord_cur = coord[idx]\n",
    "            cur.execute(f\"INSERT INTO oysters_in_photo (Ann_File_ID, Confidence, X1, Y1, X2, Y2, Class, Class_Index) VALUES ({id}, {conf[idx]}, {coord_cur[0]}, {coord_cur[1]}, {coord_cur[2]}, {coord_cur[3]}, '{names[idx]}', {class_num[idx]});\")\n",
    "        return id\n",
    "    except IntegrityError:\n",
    "        cur.execute(f\"SELECT Ann_File_ID FROM annotated_files WHERE Raw_File_ID = {Raw_File_ID} AND Model_ID = {Model_ID}\")\n",
    "        return(cur.fetchall()[-1]['Ann_File_ID'])\n",
    "cur.execute(f\"DELETE FROM oysters_in_photo WHERE Ann_File_ID = {ann_photo_id};\")  \n",
    "cur.execute(f\"DELETE FROM annotated_photos WHERE Ann_File_ID = {ann_photo_id};\")\n",
    "cur.execute(f\"DELETE FROM annotated_files WHERE Ann_File_ID = {ann_photo_id};\")\n",
    "\n",
    "ann_photo_id = ann_img(id_raw_photo, id_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35d8d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_video(Raw_File_ID, Model_ID, notes = '', f_out = './Files/Video_ann', threshold = 0.3):\n",
    "    try:\n",
    "        cur.execute(f\"SELECT * FROM raw_files WHERE Raw_File_ID = {Raw_File_ID}\")\n",
    "        cur_video = cur.fetchall()[-1]\n",
    "\n",
    "        cur.execute(f\"SELECT * FROM models WHERE Model_ID = {Model_ID}\")\n",
    "        cur_model = cur.fetchall()[-1]\n",
    "        \n",
    "        cur.execute(f\"SELECT * from annotated_files WHERE Model_ID = {Model_ID} AND Raw_File_ID = {Raw_File_ID}\")\n",
    "        res = cur.fetchall()\n",
    "        if res:\n",
    "            return res[-1]['Ann_File_ID']\n",
    "#             raise IntegrityError(\"The video has already been annotated by this model\")\n",
    "        \n",
    "        model = YOLOv10(cur_model['Model_Points_Path'])\n",
    "        \n",
    "        avg_oysters, time_s, out_path, ann_rate = annotate_video(cur_video['Filepath'], model, out_location = f_out, conf_level = threshold)\n",
    "        \n",
    "        cur.execute(f\"INSERT INTO annotated_files (Raw_File_ID, Model_ID, Annotated_Filepath, Time_to_Annotate, Confidence_Threshold, Notes, Timestamp) VALUES ('{Raw_File_ID}', '{Model_ID}', 'REPLACE', '{time_s * 1000}', {threshold}, '{notes}', CURRENT_TIMESTAMP);\")\n",
    "        \n",
    "        id = get_REPLACE_ID(column_id = 'Ann_File_ID', table='annotated_files', column_rep='Annotated_Filepath')\n",
    "        \n",
    "        f_id_name = get_id_fname(f_out, cur_video['Filepath'], id)\n",
    "        \n",
    "        cur.execute(f\"UPDATE annotated_files SET Annotated_Filepath = '{f_id_name}' WHERE Ann_File_ID = {id};\")\n",
    "\n",
    "        os.rename(out_path, f_id_name)\n",
    "\n",
    "        cur.execute(f\"INSERT INTO annotated_videos (Ann_File_ID, Annotation_Rate, Tracing, Average_Number_of_Oysters) VALUES ({id}, {ann_rate}, 0, {avg_oysters})\")\n",
    "        \n",
    "        return id\n",
    "    except IntegrityError:\n",
    "        cur.execute(f\"SELECT Ann_File_ID FROM annotated_files WHERE Raw_File_ID = {Raw_File_ID} AND Model_ID = {Model_ID}\")\n",
    "        return(cur.fetchall()[-1]['Ann_File_ID'])\n",
    "\n",
    "    \n",
    "id_vid = ann_video(id_raw_video, id_mod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba45b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_folder(\"./Files/tmp\")\n",
    "# print(os.listdir('.'))\n",
    "# os.rename('./runs/detect/train/weights/best.pt', './Files/Model/f1/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ffb203",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id_raw_photo)\n",
    "print(id_raw_video)\n",
    "print(id_rob)\n",
    "print(id_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25291475",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_folder('runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a157edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_folder('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c68e964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
